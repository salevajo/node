[cluster]

nomad_url = http://10.66.60.1:4646
consul_url = http://10.66.60.1:8500
vault_url = http://10.66.60.1:8200

# Path to ini file with vault secrets.
vault_secrets = ../cluster/var/vault-secrets.ini


[liquid]

# Domain for the liquid bundle.
domain = liquid.example.org

# User-friendly title.
# Defaults to the domain with no spaces, capitalized.
title = Liquid Example Org

# Always serving http. With https enabled, this redirects.
http_port = 80

# Set all applications in debug mode.
# Please
#        do
#           not
#               use
#                   in
#                      production.
debug = true

# Mount liquidinvestigations and hoover repositories.
mount_local_repos = false

# Path to a directory that contains clones of search and snoop.
# Defaults to ./repos/hoover
; hoover_repos_path = /path/to/hoover_org

# Path to a directory that contains a clone of liquidinvestigations/core.
# Defaults to ./repos/liquidinvestigations
; liquidinvestigations_repos_path = /path/to/liquidinvestigations_org

# Directory where docker volumes are mounted.
# This flag is used for import/export operations and checking if a collection
# has been initialized or not, so take care in setting it to the value of the
# Nomad Client meta flag "liquid_volumes".
; volumes = /path/to/volumes

# Defaults to ./collections
; collections = /path/to/collections

# Allow only staff to log in (e.g. during maintenance)
auth_staff_only = false

# Automatically kill login sessions after this time
;auth_auto_logout = 12h

# Two-factor authentication
two_factor_auth = false

# Configure memory limits for Elasticsearch
# See https://www.elastic.co/guide/en/elasticsearch/reference/6.2/heap-size.html
# Values are in MB. Defaults are:
;elasticsearch_heap_size = 1024
;elasticsearch_memory_limit = 1536

# Add elasticsearch data nodes. They will have the same resources as the master node.
# This number should only be increased. Default is 0. Set with:
elasticsearch_data_node_count = 1

# Configure memory limits for Tika
# The value is in MB. The default is:
;tika_memory_limit = 800
# Configure replication factor for tika.
# The default is 1.
;tika_count = 3

# Configure memory limits for other apps. Use this when you encounter
# "OOM Killed" messages for these services. Start with these doubled
# limits:
;hypothesis_memory_limit = 2048
;nextcloud_memory_limit = 1024

# Rate limits for Hoover API
# The value is "x,y" (x requests every y seconds)
;hoover_ratelimit_user = 30,60

# Configure memory limit for each of Hoover's 3 proxy containers (default 500MB).
# Increase if the proxies OOM when browsing large files:
;hoover_authproxy_memory_limit = 3000

# Configure memory limit (default: 300MB) and
# container count (default: 2, max: 4) for Hoover's web servers.
# These apply to both search and snoop; so actual usage will be doubled.
# Use `./liquid resources` to check the memory usage of your configuration.
# Increase in case of OOMs:
;hoover_web_memory_limit = 1500
;hoover_web_count = 3

# Sets user-facing URLs to this protocol.
# If not set, will check for the presence of the `[https]` section below.
# It makes sense to set this to `https` when another service will handle HTTPS
# termination in front of Traefik.
;http_protocol_override = https


# Uncomment this section to have Traefik use Let's Encrypt and open
# a port for HTTPS. HTTP traffic is not affected.
;[https]

;acme_email = you@yourdomain.bg
;https_port = 443
# Choose from the Let's Encrypt staging or production servers
;acme_caServer = https://acme-v02.api.letsencrypt.org/directory
;acme_caServer = https://acme-staging-v02.api.letsencrypt.org/directory


;[apps]
# Apps can be enabled or disabled here. Uncomment this section to continue.

# Shortcut; The default value is 'on'. 'liquid' and 'hoover' are always
# enabled, even if this value is set to 'off'.
;default_app_status = off

# Enable / disable each app.
# 'liquid' and 'hoover' cannot be disabled.
# All possible values are:
;nextcloud = on
;dokuwiki = on
;rocketchat = on
;hypothesis = on
;codimd = on


[deploy]

# Health check interval and timeout for all services
# Increase check_interval to lower idle system load at the cost
# of higher deploy times.
check_interval = 16s
check_timeout = 10s

# Configure how to poll health when running `./liquid deploy`
wait_max_sec = 660
wait_poll_interval = 1
wait_green_count = 6


[snoop]

# Hoover Snoop
# - `enable_workers` - set to "false" to stop all processing.
# - `min_workers_per_node` - Minimum number of workers on each node, default 2.
# - `max_workers_per_node` - Maximum number of workers on each node, default 6.
# - `worker_cpu_count_multiplier` - Each node tries to run a number of workers
#                                   equal to its CPU count multiplied by this
#                                   value. The resulting worker count is
#                                   trimmed to the (min, max) values above.
# - `rabbitmq_memory_limit` - memory limit of the queue container, expressed in Mb.
#                             Default 700, increase for larger collections.
# - `postgres_memory_limit` - shared memory limit for postgresql container.
#                             Default 1600, increase for larger collections.
# - `postgres_max_connections` - max connection count for postgresql container.
#                             All worker and server processes open one connection.
#                             Default 250, increase for larger worker pools.

enable_workers = true
min_workers_per_node = 1
max_workers_per_node = 20
worker_cpu_count_multiplier = 0.75
; rabbitmq_memory_limit = 700
; postgres_memory_limit = 2600
; postgres_max_connections = 400


[versions]
# Override versions of docker images from versions.ini:

# liquid-core = liquidinvestigations/core:latest



# Optional and Custom Jobs
# ========================

# Run a zipkin tracing system.
; [job:zipkin]
; template = templates/zipkin.nomad

# Run a custom local job, see litterbox.py
# [job:Cat]
# loader = local_jobs.litterbox.Cat



# Hoover Collections
# ==================

# - collection names are [a-z][a-z0-9] only; no underscores or dashes allowed!
# - process - Disable the queueing of tasks for this collection. Tasks already on the queue will still run.
# - sync - Enable periodic re-walking of input and imported OCR data.
# - ocr_languages: Comma-separated list of three-leter language codes for Tesseract 4.0:
#                  https://tesseract-ocr.github.io/tessdoc/Data-Files#data-files-for-version-400-november-29-2016
# Examples below.

# Collection corresponding to nextcloud uploads
; [collection:uploads]
; process = True
; sync = True
; ocr_languages = eng,ron

# Add the testdata collection. Remove if not needed.
# Be sure to clone it first:
#     git clone https://github.com/liquidinvestigations/testdata collections/testdata
; [collection:testdata]
; process = True



# Self-Hosted Continuous Integration
# ==================================
;[ci]
;runner_capacity = 2
;docker_username = NOTHING
;docker_password = EVERYTHING
;github_client_id = SOMETHING
;github_client_secret = SOMETHING_ELSE
;github_user_filter = username,organization,anything
;docker_registry_address = 10.66.60.1
;docker_registry_port = 6665
